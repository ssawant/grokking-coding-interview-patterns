{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = messages = pd.read_csv('SMSSpamCollection', sep='\\t', names=[\"label\", \"message\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(df['message']) # independent feature\n",
    "y = list(df['label']) # dependent feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       " 'ham')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=list(pd.get_dummies(y, drop_first=True)['spam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 1115)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer\n",
    "\n",
    "Steps to implements transformer for custome datasets\n",
    "1. Call the pretrained model\n",
    "2. Call the tokenizer\n",
    "3. Tokenize your datasets into encodings\n",
    "3. Convert these encodings into dataset objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Call the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Call the tokenizer and encoded yor datasets\n",
    "- Truncate : to remove white space\n",
    "- Padding : to make sentence of same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=238, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Covert these encoding into Dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 03:21:07.562583: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-24 03:21:08.322696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 333 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:4f:00.0, compute capability: 7.5\n",
      "2022-07-24 03:21:08.323536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14494 MB memory:  -> device: 1, name: Quadro RTX 5000, pci bus id: 0000:91:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    y_train\n",
    "))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    y_test\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=({'input_ids': TensorSpec(shape=(238,), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(238,), dtype=tf.int32, name=None)}, TensorSpec(shape=(), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification, TFTrainer, TFTrainingArguments\n",
    "\n",
    "training_args = TFTrainingArguments(\n",
    "    output_dir= './results',        # output directory\n",
    "    num_train_epochs=2,             # total number of training epochs\n",
    "    per_device_train_batch_size=4,   # batch size per device during training\n",
    "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
    "    warmup_steps=500,               # number of warmup stepsfor learning reate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./log',            # strength of weight decay\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 03:29:44.109686: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 89.42MiB (rounded to 93763584)requested by op TruncatedNormal\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-07-24 03:29:44.109760: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] BFCAllocator dump for GPU_0_bfc\n",
      "2022-07-24 03:29:44.109786: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (256): \tTotal Chunks: 18, Chunks in use: 18. 4.5KiB allocated for chunks. 4.5KiB in use in bin. 264B client-requested in use in bin.\n",
      "2022-07-24 03:29:44.109803: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-24 03:29:44.109818: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-07-24 03:29:44.109835: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2048): \tTotal Chunks: 46, Chunks in use: 46. 138.8KiB allocated for chunks. 138.8KiB in use in bin. 138.0KiB client-requested in use in bin.\n",
      "2022-07-24 03:29:44.109861: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4096): \tTotal Chunks: 7, Chunks in use: 7. 31.0KiB allocated for chunks. 31.0KiB in use in bin. 21.0KiB client-requested in use in bin.\n",
      "2022-07-24 03:29:44.109873: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8192): \tTotal Chunks: 5, Chunks in use: 5. 60.0KiB allocated for chunks. 60.0KiB in use in bin. 60.0KiB client-requested in use in bin.\n",
      "2022-07-24 03:29:44.109885: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16384): \tTotal Chunks: 1, Chunks in use: 0. 25.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-24 03:29:44.109898: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (32768): \tTotal Chunks: 4, Chunks in use: 2. 195.5KiB allocated for chunks. 90.0KiB in use in bin. 90.0KiB client-requested in use in bin.\n",
      "2022-07-24 03:29:44.109911: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (65536): \tTotal Chunks: 2, Chunks in use: 1. 160.0KiB allocated for chunks. 76.2KiB in use in bin. 45.0KiB client-requested in use in bin.\n",
      "2022-07-24 03:29:44.109922: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-24 03:29:44.109932: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-24 03:29:44.109941: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-24 03:29:44.109951: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1048576): \tTotal Chunks: 2, Chunks in use: 1. 3.44MiB allocated for chunks. 1.50MiB in use in bin. 1.50MiB client-requested in use in bin.\n",
      "2022-07-24 03:29:44.109964: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2097152): \tTotal Chunks: 26, Chunks in use: 24. 58.96MiB allocated for chunks. 54.46MiB in use in bin. 54.00MiB client-requested in use in bin.\n",
      "2022-07-24 03:29:44.109973: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-24 03:29:44.109985: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8388608): \tTotal Chunks: 11, Chunks in use: 11. 99.00MiB allocated for chunks. 99.00MiB in use in bin. 99.00MiB client-requested in use in bin.\n",
      "2022-07-24 03:29:44.109996: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16777216): \tTotal Chunks: 1, Chunks in use: 1. 16.84MiB allocated for chunks. 16.84MiB in use in bin. 9.00MiB client-requested in use in bin.\n",
      "2022-07-24 03:29:44.110006: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-24 03:29:44.110015: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-24 03:29:44.110027: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 1. 154.72MiB allocated for chunks. 154.72MiB in use in bin. 89.42MiB client-requested in use in bin.\n",
      "2022-07-24 03:29:44.110044: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-24 03:29:44.110056: I tensorflow/core/common_runtime/bfc_allocator.cc:1050] Bin for 89.42MiB was 64.00MiB, Chunk State: \n",
      "2022-07-24 03:29:44.110065: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 349765632\n",
      "2022-07-24 03:29:44.110083: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6000000 of size 1280 next 1\n",
      "2022-07-24 03:29:44.110092: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6000500 of size 256 next 2\n",
      "2022-07-24 03:29:44.110100: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6000600 of size 256 next 3\n",
      "2022-07-24 03:29:44.110108: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6000700 of size 256 next 4\n",
      "2022-07-24 03:29:44.110115: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6000800 of size 256 next 5\n",
      "2022-07-24 03:29:44.110123: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6000900 of size 256 next 6\n",
      "2022-07-24 03:29:44.110130: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6000a00 of size 256 next 7\n",
      "2022-07-24 03:29:44.110138: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6000b00 of size 256 next 8\n",
      "2022-07-24 03:29:44.110145: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6000c00 of size 256 next 9\n",
      "2022-07-24 03:29:44.110153: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6000d00 of size 3072 next 13\n",
      "2022-07-24 03:29:44.110163: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6001900 of size 3840 next 31\n",
      "2022-07-24 03:29:44.110171: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6002800 of size 256 next 34\n",
      "2022-07-24 03:29:44.110178: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6002900 of size 256 next 35\n",
      "2022-07-24 03:29:44.110186: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6002a00 of size 3072 next 36\n",
      "2022-07-24 03:29:44.110194: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6003600 of size 3072 next 37\n",
      "2022-07-24 03:29:44.110202: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6004200 of size 12288 next 39\n",
      "2022-07-24 03:29:44.110210: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6007200 of size 256 next 45\n",
      "2022-07-24 03:29:44.110217: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6007300 of size 256 next 46\n",
      "2022-07-24 03:29:44.110225: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6007400 of size 3072 next 38\n",
      "2022-07-24 03:29:44.110233: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6008000 of size 3072 next 47\n",
      "2022-07-24 03:29:44.110241: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6008c00 of size 3072 next 48\n",
      "2022-07-24 03:29:44.110248: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6009800 of size 3072 next 49\n",
      "2022-07-24 03:29:44.110256: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b600a400 of size 3072 next 53\n",
      "2022-07-24 03:29:44.110264: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b600b000 of size 3072 next 55\n",
      "2022-07-24 03:29:44.110272: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b600bc00 of size 4352 next 22\n",
      "2022-07-24 03:29:44.110303: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b600cd00 of size 3072 next 27\n",
      "2022-07-24 03:29:44.110311: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b600d900 of size 3072 next 78\n",
      "2022-07-24 03:29:44.110321: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b600e500 of size 12288 next 89\n",
      "2022-07-24 03:29:44.110329: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6011500 of size 3072 next 96\n",
      "2022-07-24 03:29:44.110336: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6012100 of size 3072 next 97\n",
      "2022-07-24 03:29:44.110345: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6012d00 of size 3072 next 98\n",
      "2022-07-24 03:29:44.110353: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6013900 of size 3072 next 86\n",
      "2022-07-24 03:29:44.110361: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6014500 of size 3072 next 100\n",
      "2022-07-24 03:29:44.110369: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6015100 of size 3072 next 104\n",
      "2022-07-24 03:29:44.110376: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6015d00 of size 4352 next 108\n",
      "2022-07-24 03:29:44.110384: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6016e00 of size 3072 next 109\n",
      "2022-07-24 03:29:44.110392: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6017a00 of size 3072 next 105\n",
      "2022-07-24 03:29:44.110399: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6018600 of size 3072 next 111\n",
      "2022-07-24 03:29:44.110407: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6019200 of size 3072 next 113\n",
      "2022-07-24 03:29:44.110415: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6019e00 of size 5120 next 16\n",
      "2022-07-24 03:29:44.110424: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b601b200 of size 256 next 17\n",
      "2022-07-24 03:29:44.110431: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b601b300 of size 3072 next 18\n",
      "2022-07-24 03:29:44.110439: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b601bf00 of size 256 next 19\n",
      "2022-07-24 03:29:44.110447: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b601c000 of size 3072 next 20\n",
      "2022-07-24 03:29:44.110454: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b601cc00 of size 256 next 21\n",
      "2022-07-24 03:29:44.110462: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b601cd00 of size 256 next 24\n",
      "2022-07-24 03:29:44.110470: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b601ce00 of size 3072 next 29\n",
      "2022-07-24 03:29:44.110478: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b601da00 of size 12288 next 58\n",
      "2022-07-24 03:29:44.110485: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6020a00 of size 3072 next 64\n",
      "2022-07-24 03:29:44.110493: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6021600 of size 3072 next 65\n",
      "2022-07-24 03:29:44.110501: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6022200 of size 3072 next 66\n",
      "2022-07-24 03:29:44.110508: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6022e00 of size 3072 next 63\n",
      "2022-07-24 03:29:44.110516: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6023a00 of size 3072 next 68\n",
      "2022-07-24 03:29:44.110524: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6024600 of size 3072 next 72\n",
      "2022-07-24 03:29:44.110532: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6025200 of size 4352 next 76\n",
      "2022-07-24 03:29:44.110539: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6026300 of size 3072 next 77\n",
      "2022-07-24 03:29:44.110547: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6026f00 of size 3072 next 75\n",
      "2022-07-24 03:29:44.110555: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6027b00 of size 4864 next 30\n",
      "2022-07-24 03:29:44.110563: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6028e00 of size 256 next 33\n",
      "2022-07-24 03:29:44.110572: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6028f00 of size 3072 next 82\n",
      "2022-07-24 03:29:44.110580: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7fc6b6029b00 of size 85760 next 25\n",
      "2022-07-24 03:29:44.110588: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b603ea00 of size 46080 next 26\n",
      "2022-07-24 03:29:44.110598: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6049e00 of size 2846208 next 11\n",
      "2022-07-24 03:29:44.110606: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6300c00 of size 1572864 next 12\n",
      "2022-07-24 03:29:44.110614: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6480c00 of size 12288 next 80\n",
      "2022-07-24 03:29:44.110622: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6483c00 of size 3072 next 83\n",
      "2022-07-24 03:29:44.110629: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6484800 of size 3072 next 84\n",
      "2022-07-24 03:29:44.110637: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6485400 of size 3072 next 115\n",
      "2022-07-24 03:29:44.110645: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6486000 of size 3072 next 114\n",
      "2022-07-24 03:29:44.110653: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6486c00 of size 3072 next 120\n",
      "2022-07-24 03:29:44.110661: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6487800 of size 4352 next 123\n",
      "2022-07-24 03:29:44.110668: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6488900 of size 3072 next 124\n",
      "2022-07-24 03:29:44.110676: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6489500 of size 3072 next 121\n",
      "2022-07-24 03:29:44.110684: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b648a100 of size 256 next 122\n",
      "2022-07-24 03:29:44.110692: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7fc6b648a200 of size 26112 next 107\n",
      "2022-07-24 03:29:44.110700: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6490800 of size 12288 next 110\n",
      "2022-07-24 03:29:44.110708: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7fc6b6493800 of size 61440 next 52\n",
      "2022-07-24 03:29:44.110716: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b64a2800 of size 3072 next 59\n",
      "2022-07-24 03:29:44.110725: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b64a3400 of size 3072 next 57\n",
      "2022-07-24 03:29:44.110733: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b64a4000 of size 3072 next 88\n",
      "2022-07-24 03:29:44.110741: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b64a4c00 of size 4352 next 92\n",
      "2022-07-24 03:29:44.110749: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b64a5d00 of size 3072 next 93\n",
      "2022-07-24 03:29:44.110757: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b64a6900 of size 3072 next 90\n",
      "2022-07-24 03:29:44.110765: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b64a7500 of size 46080 next 127\n",
      "2022-07-24 03:29:44.110772: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7fc6b64b2900 of size 46592 next 119\n",
      "2022-07-24 03:29:44.110781: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b64bdf00 of size 78080 next 101\n",
      "2022-07-24 03:29:44.110790: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7fc6b64d1000 of size 2030592 next 14\n",
      "2022-07-24 03:29:44.110798: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b66c0c00 of size 2359296 next 15\n",
      "2022-07-24 03:29:44.110807: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6900c00 of size 2359296 next 23\n",
      "2022-07-24 03:29:44.110815: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6b40c00 of size 2359296 next 28\n",
      "2022-07-24 03:29:44.110823: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7fc6b6d80c00 of size 2359296 next 40\n",
      "2022-07-24 03:29:44.110831: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b6fc0c00 of size 2359296 next 41\n",
      "2022-07-24 03:29:44.110840: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b7200c00 of size 2359296 next 43\n",
      "2022-07-24 03:29:44.110848: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b7440c00 of size 2359296 next 50\n",
      "2022-07-24 03:29:44.110856: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b7680c00 of size 2359296 next 54\n",
      "2022-07-24 03:29:44.110864: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b78c0c00 of size 2359296 next 61\n",
      "2022-07-24 03:29:44.110873: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b7b00c00 of size 2359296 next 51\n",
      "2022-07-24 03:29:44.110881: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b7d40c00 of size 2359296 next 67\n",
      "2022-07-24 03:29:44.110889: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b7f80c00 of size 2359296 next 71\n",
      "2022-07-24 03:29:44.110897: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7fc6b81c0c00 of size 2359296 next 42\n",
      "2022-07-24 03:29:44.110906: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b8400c00 of size 9437184 next 32\n",
      "2022-07-24 03:29:44.110915: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b8d00c00 of size 9437184 next 44\n",
      "2022-07-24 03:29:44.110923: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b9600c00 of size 2359296 next 69\n",
      "2022-07-24 03:29:44.110931: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b9840c00 of size 2359296 next 79\n",
      "2022-07-24 03:29:44.110939: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b9a80c00 of size 2359296 next 87\n",
      "2022-07-24 03:29:44.110947: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b9cc0c00 of size 2359296 next 60\n",
      "2022-07-24 03:29:44.110955: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6b9f00c00 of size 9437184 next 62\n",
      "2022-07-24 03:29:44.110963: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6ba800c00 of size 9437184 next 56\n",
      "2022-07-24 03:29:44.110971: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6bb100c00 of size 2359296 next 70\n",
      "2022-07-24 03:29:44.110979: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6bb340c00 of size 2359296 next 99\n",
      "2022-07-24 03:29:44.110987: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6bb580c00 of size 2359296 next 103\n",
      "2022-07-24 03:29:44.110996: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6bb7c0c00 of size 2359296 next 73\n",
      "2022-07-24 03:29:44.111004: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6bba00c00 of size 9437184 next 74\n",
      "2022-07-24 03:29:44.111012: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6bc300c00 of size 9437184 next 81\n",
      "2022-07-24 03:29:44.111020: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6bcc00c00 of size 2359296 next 102\n",
      "2022-07-24 03:29:44.111029: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6bce40c00 of size 2359296 next 116\n",
      "2022-07-24 03:29:44.111037: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6bd080c00 of size 2359296 next 118\n",
      "2022-07-24 03:29:44.111045: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6bd2c0c00 of size 2359296 next 91\n",
      "2022-07-24 03:29:44.111053: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6bd500c00 of size 9437184 next 85\n",
      "2022-07-24 03:29:44.111061: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6bde00c00 of size 9437184 next 95\n",
      "2022-07-24 03:29:44.111070: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6be700c00 of size 9437184 next 106\n",
      "2022-07-24 03:29:44.111078: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6bf000c00 of size 9437184 next 94\n",
      "2022-07-24 03:29:44.111086: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6bf900c00 of size 9437184 next 112\n",
      "2022-07-24 03:29:44.111095: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6c0200c00 of size 17657856 next 10\n",
      "2022-07-24 03:29:44.111104: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fc6c12d7c00 of size 162235392 next 18446744073709551615\n",
      "2022-07-24 03:29:44.111115: I tensorflow/core/common_runtime/bfc_allocator.cc:1088]      Summary of in-use Chunks by size: \n",
      "2022-07-24 03:29:44.111126: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 18 Chunks of size 256 totalling 4.5KiB\n",
      "2022-07-24 03:29:44.111136: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-07-24 03:29:44.111146: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 45 Chunks of size 3072 totalling 135.0KiB\n",
      "2022-07-24 03:29:44.111156: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 3840 totalling 3.8KiB\n",
      "2022-07-24 03:29:44.111165: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 5 Chunks of size 4352 totalling 21.2KiB\n",
      "2022-07-24 03:29:44.111174: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 4864 totalling 4.8KiB\n",
      "2022-07-24 03:29:44.111183: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 5120 totalling 5.0KiB\n",
      "2022-07-24 03:29:44.111192: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 5 Chunks of size 12288 totalling 60.0KiB\n",
      "2022-07-24 03:29:44.111201: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 46080 totalling 90.0KiB\n",
      "2022-07-24 03:29:44.111211: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 78080 totalling 76.2KiB\n",
      "2022-07-24 03:29:44.111221: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1572864 totalling 1.50MiB\n",
      "2022-07-24 03:29:44.111231: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 23 Chunks of size 2359296 totalling 51.75MiB\n",
      "2022-07-24 03:29:44.111240: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 2846208 totalling 2.71MiB\n",
      "2022-07-24 03:29:44.111249: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 11 Chunks of size 9437184 totalling 99.00MiB\n",
      "2022-07-24 03:29:44.111258: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 17657856 totalling 16.84MiB\n",
      "2022-07-24 03:29:44.111268: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 162235392 totalling 154.72MiB\n",
      "2022-07-24 03:29:44.111278: I tensorflow/core/common_runtime/bfc_allocator.cc:1095] Sum Total of in-use chunks: 326.92MiB\n",
      "2022-07-24 03:29:44.111287: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] total_region_allocated_bytes_: 349765632 memory_limit_: 349765632 available bytes: 0 curr_region_allocation_bytes_: 699531264\n",
      "2022-07-24 03:29:44.111303: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] Stats: \n",
      "Limit:                       349765632\n",
      "InUse:                       342796544\n",
      "MaxInUse:                    349765632\n",
      "NumAllocs:                         512\n",
      "MaxAllocSize:                162235392\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-07-24 03:29:44.111332: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ****************************************************x****************************xxxxxxxxxxxxxxxxxxx\n",
      "2022-07-24 03:29:44.111397: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at random_op.cc:74 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[30522,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer \"distilbert\" (type TFDistilBertMainLayer).\n\nOOM when allocating tensor with shape[30522,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:TruncatedNormal]\n\nCall arguments received by layer \"distilbert\" (type TFDistilBertMainLayer):\n  • input_ids=tf.Tensor(shape=(3, 5), dtype=int32)\n  • attention_mask=None\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/santosh/Development/grokking-coding-interview-patterns/Machine Learning/Natural Language Processing/BERT Project SMS Spam Classifier.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.60.60.202/home/santosh/Development/grokking-coding-interview-patterns/Machine%20Learning/Natural%20Language%20Processing/BERT%20Project%20SMS%20Spam%20Classifier.ipynb#ch0000018vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m training_args\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mscope():\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.60.60.202/home/santosh/Development/grokking-coding-interview-patterns/Machine%20Learning/Natural%20Language%20Processing/BERT%20Project%20SMS%20Spam%20Classifier.ipynb#ch0000018vscode-remote?line=1'>2</a>\u001b[0m     model \u001b[39m=\u001b[39m TFDistilBertForSequenceClassification\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mdistilbert-base-uncased\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.60.60.202/home/santosh/Development/grokking-coding-interview-patterns/Machine%20Learning/Natural%20Language%20Processing/BERT%20Project%20SMS%20Spam%20Classifier.ipynb#ch0000018vscode-remote?line=3'>4</a>\u001b[0m trainer \u001b[39m=\u001b[39m TFTrainer(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.60.60.202/home/santosh/Development/grokking-coding-interview-patterns/Machine%20Learning/Natural%20Language%20Processing/BERT%20Project%20SMS%20Spam%20Classifier.ipynb#ch0000018vscode-remote?line=4'>5</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,                    \u001b[39m# Transformers model to be trained\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.60.60.202/home/santosh/Development/grokking-coding-interview-patterns/Machine%20Learning/Natural%20Language%20Processing/BERT%20Project%20SMS%20Spam%20Classifier.ipynb#ch0000018vscode-remote?line=5'>6</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,             \u001b[39m# training arguments, define above\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.60.60.202/home/santosh/Development/grokking-coding-interview-patterns/Machine%20Learning/Natural%20Language%20Processing/BERT%20Project%20SMS%20Spam%20Classifier.ipynb#ch0000018vscode-remote?line=6'>7</a>\u001b[0m     train_dataset\u001b[39m=\u001b[39mtrain_dataset,    \u001b[39m# training dataset\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.60.60.202/home/santosh/Development/grokking-coding-interview-patterns/Machine%20Learning/Natural%20Language%20Processing/BERT%20Project%20SMS%20Spam%20Classifier.ipynb#ch0000018vscode-remote?line=7'>8</a>\u001b[0m     eval_dataset\u001b[39m=\u001b[39mtest_dataset       \u001b[39m# evaluation dataset\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.60.60.202/home/santosh/Development/grokking-coding-interview-patterns/Machine%20Learning/Natural%20Language%20Processing/BERT%20Project%20SMS%20Spam%20Classifier.ipynb#ch0000018vscode-remote?line=8'>9</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.virtualenvs/vmlimpl/lib/python3.8/site-packages/transformers/modeling_tf_utils.py:1803\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1801\u001b[0m         model(model\u001b[39m.\u001b[39mdummy_inputs)  \u001b[39m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   1802\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1803\u001b[0m     model(model\u001b[39m.\u001b[39;49mdummy_inputs)  \u001b[39m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   1805\u001b[0m \u001b[39massert\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(resolved_archive_file), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError retrieving file \u001b[39m\u001b[39m{\u001b[39;00mresolved_archive_file\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1806\u001b[0m \u001b[39m# 'by_name' allow us to do transfer learning by skipping/adding layers\u001b[39;00m\n\u001b[1;32m   1807\u001b[0m \u001b[39m# see https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/python/keras/engine/network.py#L1339-L1357\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/vmlimpl/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.virtualenvs/vmlimpl/lib/python3.8/site-packages/transformers/modeling_tf_utils.py:383\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m main_input \u001b[39m=\u001b[39m fn_args_and_kwargs\u001b[39m.\u001b[39mpop(main_input_name, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    382\u001b[0m unpacked_inputs \u001b[39m=\u001b[39m input_processing(func, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig, main_input, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 383\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49munpacked_inputs)\n",
      "File \u001b[0;32m~/.virtualenvs/vmlimpl/lib/python3.8/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py:742\u001b[0m, in \u001b[0;36mTFDistilBertForSequenceClassification.call\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, labels, training)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[39m@unpack_inputs\u001b[39m\n\u001b[1;32m    717\u001b[0m \u001b[39m@add_start_docstrings_to_model_forward\u001b[39m(DISTILBERT_INPUTS_DOCSTRING\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39mbatch_size, sequence_length\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    718\u001b[0m \u001b[39m@add_code_sample_docstrings\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    734\u001b[0m     training: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    735\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[TFSequenceClassifierOutput, Tuple[tf\u001b[39m.\u001b[39mTensor]]:\n\u001b[1;32m    736\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    737\u001b[0m \u001b[39m    labels (`tf.Tensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[39m        Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[39m        config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[39m        `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 742\u001b[0m     distilbert_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistilbert(\n\u001b[1;32m    743\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    744\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    745\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    746\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    747\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    748\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    749\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    750\u001b[0m         training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m    751\u001b[0m     )\n\u001b[1;32m    752\u001b[0m     hidden_state \u001b[39m=\u001b[39m distilbert_output[\u001b[39m0\u001b[39m]  \u001b[39m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m    753\u001b[0m     pooled_output \u001b[39m=\u001b[39m hidden_state[:, \u001b[39m0\u001b[39m]  \u001b[39m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/vmlimpl/lib/python3.8/site-packages/transformers/modeling_tf_utils.py:383\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m main_input \u001b[39m=\u001b[39m fn_args_and_kwargs\u001b[39m.\u001b[39mpop(main_input_name, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    382\u001b[0m unpacked_inputs \u001b[39m=\u001b[39m input_processing(func, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig, main_input, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 383\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49munpacked_inputs)\n",
      "File \u001b[0;32m~/.virtualenvs/vmlimpl/lib/python3.8/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py:400\u001b[0m, in \u001b[0;36mTFDistilBertMainLayer.call\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    398\u001b[0m     head_mask \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_hidden_layers\n\u001b[0;32m--> 400\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(input_ids, inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m    401\u001b[0m tfmr_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer(\n\u001b[1;32m    402\u001b[0m     embedding_output,\n\u001b[1;32m    403\u001b[0m     attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    408\u001b[0m     training\u001b[39m=\u001b[39mtraining,\n\u001b[1;32m    409\u001b[0m )\n\u001b[1;32m    411\u001b[0m \u001b[39mreturn\u001b[39;00m tfmr_output\n",
      "File \u001b[0;32m~/.virtualenvs/vmlimpl/lib/python3.8/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py:88\u001b[0m, in \u001b[0;36mTFEmbeddings.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild\u001b[39m(\u001b[39mself\u001b[39m, input_shape: tf\u001b[39m.\u001b[39mTensorShape):\n\u001b[1;32m     87\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mword_embeddings\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 88\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_weight(\n\u001b[1;32m     89\u001b[0m             name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     90\u001b[0m             shape\u001b[39m=\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim],\n\u001b[1;32m     91\u001b[0m             initializer\u001b[39m=\u001b[39mget_initializer(initializer_range\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitializer_range),\n\u001b[1;32m     92\u001b[0m         )\n\u001b[1;32m     94\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mposition_embeddings\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     95\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_weight(\n\u001b[1;32m     96\u001b[0m             name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     97\u001b[0m             shape\u001b[39m=\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_position_embeddings, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim],\n\u001b[1;32m     98\u001b[0m             initializer\u001b[39m=\u001b[39mget_initializer(initializer_range\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitializer_range),\n\u001b[1;32m     99\u001b[0m         )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"distilbert\" (type TFDistilBertMainLayer).\n\nOOM when allocating tensor with shape[30522,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:TruncatedNormal]\n\nCall arguments received by layer \"distilbert\" (type TFDistilBertMainLayer):\n  • input_ids=tf.Tensor(shape=(3, 5), dtype=int32)\n  • attention_mask=None\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with training_args.strategy.scope():\n",
    "    model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "trainer = TFTrainer(\n",
    "    model=model,                    # Transformers model to be trained\n",
    "    args=training_args,             # training arguments, define above\n",
    "    train_dataset=train_dataset,    # training dataset\n",
    "    eval_dataset=test_dataset       # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.predict(test_dataset)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=trainer.predict(test_dataset)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('senti_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing the model\n",
    "\n",
    "https://simpletransformers.ai/docs/installation/\n",
    "\n",
    "- wandDB: Analysis Weight and Biases\n",
    "\n",
    "If you want to change how the model itself is built, you can define your custom configuration class. Each architecture comes with its own relevant configuration (in the case of DistilBERT, DistilBertConfig) which allows you to specify any of the hidden dimension, dropout rate, etc. If you do core modifications, like changing the hidden size, you won't be able to use a pretrained model anymore and will need to train from scratch. You would then instantiate the model directly from this configuration.\n",
    "\n",
    "Here we use the predefined vocabulary of DistilBERT (hence load the tokenizer with the DistilBertTokenizer.from_pretrained method) and initialize the model from scratch (hence instantiate the model from the configuration instead of using the DistilBertForSequenceClassification.from_pretrained method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertConfig, DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "config = DistilBertConfig(n_heads=8, dim=512, hidden_dim=4*512)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = TFDistilBertForSequenceClassification(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('vmlimpl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7626a37170bde8cbd07d8d30684bdff5f1c1a26dbdf249b53898a22fb9c20fab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
